{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5ce83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:246: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: OpenAI gym not installed.\n"
     ]
    }
   ],
   "source": [
    "# System and processing\n",
    "import sys\n",
    "import dill as pickle\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "import multiprocessing\n",
    "from pathos.multiprocessing import ProcessingPool, ThreadingPool\n",
    "from multiprocessing import Manager\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations, combinations\n",
    "\n",
    "\n",
    "# Common math packages\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# External packages\n",
    "import sage.all\n",
    "import sage.geometry.polyhedron.base as Polyhedron\n",
    "\n",
    "# Codes\n",
    "import params_team\n",
    "from simple_rl.agents import FixedPolicyAgent\n",
    "from simple_rl.planning import ValueIteration\n",
    "from simple_rl.utils import make_mdp\n",
    "from policy_summarization import bayesian_IRL\n",
    "from policy_summarization import policy_summarization_helpers as ps_helpers\n",
    "from policy_summarization import BEC\n",
    "import policy_summarization.multiprocessing_helpers as mp_helpers\n",
    "from simple_rl.utils import mdp_helpers\n",
    "import policy_summarization.BEC_helpers as BEC_helpers\n",
    "import policy_summarization.BEC_visualization as BEC_viz\n",
    "from teams import particle_filter_team as pf_team\n",
    "import teams.teams_helpers as team_helpers\n",
    "import simulation.sim_helpers as sim_helpers\n",
    "import teams.utils_teams as utils_teams\n",
    "from analyze_sim_data import run_analysis_script\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from termcolor import colored\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = '1.0'\n",
    "mpl.rcParams['axes.labelsize'] = 'x-large'\n",
    "mpl.rcParams['xtick.labelsize'] = 'large'\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "\n",
    "# Other imports.\n",
    "sys.path.append(\"simple_rl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f74e546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_policies(params, pool, lock):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the minimum BEC constranints for the domain. Need to load into the database.\n",
    "    \"\"\"\n",
    "\n",
    "    ps_helpers.obtain_env_policies(params.mdp_class, params.data_loc['BEC'], np.expand_dims(params.weights['val'], axis=0), params.mdp_parameters, pool, lock)\n",
    "\n",
    "    # get base constraints for all the environments and demonstrations\n",
    "    try:\n",
    "        with lock:\n",
    "            with open('models/' + params.data_loc['BEC'] + '/team_base_constraints.pickle', 'rb') as f:\n",
    "                policy_constraints, min_subset_constraints_record, env_record, traj_record, traj_features_record, reward_record, mdp_features_record, consistent_state_count = pickle.load(f)\n",
    "    except:\n",
    "        # use policy BEC to extract constraints\n",
    "        policy_constraints, min_subset_constraints_record, env_record, traj_record, traj_features_record, reward_record, mdp_features_record, consistent_state_count = BEC.extract_constraints(params.data_loc['BEC'], params.BEC['BEC_depth'], params.step_cost_flag, pool, lock, print_flag=True)\n",
    "        with lock:\n",
    "            with open('models/' + params.data_loc['BEC'] + '/team_base_constraints.pickle', 'wb') as f:\n",
    "                pickle.dump((policy_constraints, min_subset_constraints_record, env_record, traj_record, traj_features_record, reward_record, mdp_features_record, consistent_state_count), f)\n",
    "\n",
    "    # get BEC constraints\n",
    "    try:\n",
    "        with lock:\n",
    "            with open('models/' + params.data_loc['BEC'] + '/team_BEC_constraints.pickle', 'rb') as f:\n",
    "                min_BEC_constraints, BEC_lengths_record = pickle.load(f)\n",
    "    except:\n",
    "        min_BEC_constraints, BEC_lengths_record = BEC.extract_BEC_constraints(policy_constraints, min_subset_constraints_record, env_record, params.weights['val'], params.step_cost_flag, pool)\n",
    "        with lock:\n",
    "            with open('models/' + params.data_loc['BEC'] + '/team_BEC_constraints.pickle', 'wb') as f:\n",
    "                pickle.dump((min_BEC_constraints, BEC_lengths_record), f)\n",
    "        \n",
    "    return min_subset_constraints_record, env_record, traj_record, traj_features_record, mdp_features_record, consistent_state_count, min_BEC_constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833b1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pool_processes(the_lock):\n",
    "    '''Initialize each process with a global variable lock.\n",
    "    '''\n",
    "    global file_lock\n",
    "    lock = the_lock\n",
    "\n",
    "\n",
    "class NoDaemonProcess(multiprocessing.Process):\n",
    "    \n",
    "    def __init__(self, lock, *args, **kwargs):\n",
    "        self._lock = lock\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    \n",
    "    # make 'daemon' attribute always return False\n",
    "    @property\n",
    "    def daemon(self):\n",
    "        return False\n",
    "\n",
    "    @daemon.setter\n",
    "    def daemon(self, val):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def lock(self):\n",
    "        return self._lock\n",
    "    \n",
    "    def set_lock(self, lock):\n",
    "        self._lock = lock\n",
    "\n",
    "    def run(self):\n",
    "        if self._lock:\n",
    "            init_pool_processes(self._lock)\n",
    "        super().run()\n",
    "\n",
    "\n",
    "class NoDaemonProcessPool(multiprocessing.pool.Pool):\n",
    "\n",
    "    def __init__(self, processes=None, lock=None, *args, **kwargs):\n",
    "        self._lock = lock\n",
    "        super().__init__(processes=processes, initializer=self.init_pool_processes, *args, **kwargs)\n",
    "\n",
    "    def init_pool_processes(self):\n",
    "        global lock\n",
    "        lock = self._lock\n",
    "\n",
    "    def Process(self, *args, **kwds):\n",
    "        proc = super(NoDaemonProcessPool, self).Process(*args, **kwds)\n",
    "        proc.__class__ = NoDaemonProcess\n",
    "        proc._lock = self._lock  # Pass the lock to the process\n",
    "\n",
    "        return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad4b3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_teaching(params, teacher_learning_factor, pool, lock):\n",
    "    \n",
    "    min_subset_constraints_record, env_record, traj_record, traj_features_record, mdp_features_record, consistent_state_count, min_BEC_constraints = get_optimal_policies(params, pool, lock)\n",
    "\n",
    "    \n",
    "    team_prior, particles_team_teacher = team_helpers.sample_team_pf(params.team_size, params.BEC['n_particles'], params.weights['val'], params.step_cost_flag, teacher_learning_factor=teacher_learning_factor, team_prior = params.team_prior, model_type = params.teacher_update_model_type)\n",
    "    \n",
    "    variable_filter, nonzero_counter, teaching_complete_flag = team_helpers.check_and_update_variable_filter(min_subset_constraints_record, initialize_filter_flag=True)\n",
    "    \n",
    "    visited_env_traj_idxs, min_BEC_constraints_running = [], []\n",
    "    \n",
    "    return particles_team_teacher,  variable_filter, nonzero_counter, min_BEC_constraints_running, visited_env_traj_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7ab366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_teaching_loop(params, args):\n",
    "    \n",
    "    particles_demo, summary_pool, lock, variable_filter, min_BEC_constraints_running, visited_env_traj_idxs, pool, lock = args\n",
    "    \n",
    "    # fixed variables (maybe better to read from file)\n",
    "    min_subset_constraints_record, env_record, traj_record, traj_features_record, mdp_features_record, consistent_state_count, min_BEC_constraints = get_optimal_policies(params, pool, lock)\n",
    "    teacher_uf_demo = 0.8\n",
    "    \n",
    "    # check if learning is complete\n",
    "    \n",
    "    \n",
    "    \n",
    "    # generate demos\n",
    "    demonstration, _, _, min_BEC_constraints_running, visited_env_traj_idxs, particles_demo = team_helpers.obtain_team_summary(params.data_loc['BEC'], min_subset_constraints_record, min_BEC_constraints, env_record, traj_record, mdp_features_record, params.weights['val'], params.step_cost_flag, \n",
    "                                                                                                            summary_pool, lock, params.BEC['n_human_models'], params.BEC['n_human_models_precomputed'], consistent_state_count, params.BEC['n_train_demos'], particles_demo, teacher_uf_demo, [], params.teacher_update_model_type, \n",
    "                                                                                                            variable_filter, [], [], 0, min_BEC_constraints_running, visited_env_traj_idxs)        \n",
    "      \n",
    "    if len(demonstration) == 0:\n",
    "        print('No new demonstrations possible!')\n",
    "        repeat_prev_demo_flag = True\n",
    "    else:\n",
    "        repeat_prev_demo_flag = False\n",
    "        \n",
    "        \n",
    "    # obtain diagnostic tests\n",
    "    unit_constraints, demo_ids, running_variable_filter_unit = team_helpers.show_demonstrations(demonstration, particles_demo, params.mdp_class, params.weights['val'], loop_count, viz_flag = demo_viz_flag)\n",
    "    min_KC_constraints = BEC_helpers.remove_redundant_constraints(unit_constraints, params.weights['val'], params.step_cost_flag)\n",
    "    preliminary_tests, visited_env_traj_idxs = team_helpers.obtain_diagnostic_tests(lock, params.data_loc['BEC'], demonstration, visited_env_traj_idxs, min_KC_constraints, min_subset_constraints_record, traj_record, traj_features_record, running_variable_filter_unit, mdp_features_record)\n",
    "\n",
    "    demo_mdps = []\n",
    "    for demo in demonstration:\n",
    "        demo_mdps.append(demo[0])  #Demo MDP\n",
    "        \n",
    "    test_mdps = []\n",
    "    for test in preliminary_tests:\n",
    "        test_mdps.append([test[0], test[1]]) #Test MDP and Optimal Trajectory\n",
    "        \n",
    "        \n",
    "    return demo_mpds, test_mdps, variable_filter, min_BEC_constraints_running, visited_env_traj_idxs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6653751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving for the optimal policy in each environment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing particle filter..\n",
      "num_points:  500\n",
      "Updating particles for  p1 with prior knowledge in  noise  condition...\n",
      "Initializing particle filter..\n",
      "num_points:  500\n",
      "Updating particles for  p2 with prior knowledge in  noise  condition...\n",
      "Initializing particle filter..\n",
      "num_points:  500\n",
      "Updating particles for  p3 with prior knowledge in  noise  condition...\n",
      "num_points:  500\n",
      "Team knowledge:  {'p1': [[array([[ 0,  0, -1]])]], 'p2': [[array([[ 0,  0, -1]])]], 'p3': [[array([[ 0,  0, -1]])]], 'common_knowledge': [[array([[ 0,  0, -1]])]], 'joint_knowledge': [[[array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])]]]}\n",
      "num_points:  500\n",
      "team_prior[joint_knowledge]:  [[[array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])]]]\n",
      "Update JK with constraints: [[array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])], [array([[ 0,  0, -1]])]]\n",
      "Solving for the optimal policy in each environment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_points:  2500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d6abf72ef766>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticles_demo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_BEC_constraints_running\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited_env_traj_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdemo_mpds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mdps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mariable_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_BEC_constraints_running\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited_env_traj_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_teaching_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-2b86756a902f>\u001b[0m in \u001b[0;36mrun_teaching_loop\u001b[0;34m(params, args)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# generate demos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     demonstration, _, _, min_BEC_constraints_running, visited_env_traj_idxs, particles_demo = team_helpers.obtain_team_summary(params.data_loc['BEC'], min_subset_constraints_record, min_BEC_constraints, env_record, traj_record, mdp_features_record, params.weights['val'], params.step_cost_flag, \n\u001b[0m\u001b[1;32m     15\u001b[0m                                                                                                             \u001b[0msummary_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_human_models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_human_models_precomputed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsistent_state_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_train_demos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticles_demo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_uf_demo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_update_model_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                                                                             variable_filter, [], [], 0, min_BEC_constraints_running, visited_env_traj_idxs)        \n",
      "\u001b[0;32m/mnt/g/My Drive/Research/Project_proficiency_communication_teams/Codes/augmented_taxi/teams/teams_helpers.py\u001b[0m in \u001b[0;36mobtain_team_summary\u001b[0;34m(data_loc, run_env_loc, min_subset_constraints_record, min_BEC_constraints, env_record, traj_record, mdp_features_record, weights, step_cost_flag, pool, lock, n_human_models, consistent_state_count, n_train_demos, particles_demo, teacher_uf_demo, knowledge_id, variable_filter, nonzero_counter, BEC_summary, summary_count, min_BEC_constraints_running, visited_env_traj_idxs, obj_func_proportion, vars_filename)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummary_variant\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'counterfactual'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         BEC_summary, summary_count, min_BEC_constraints_running, visited_env_traj_idxs, particles_demo = obtain_summary_counterfactual_team(data_loc, run_env_loc, particles_demo, teacher_uf_demo, knowledge_id, variable_filter, nonzero_counter, min_subset_constraints_record, min_BEC_constraints, env_record, traj_record, mdp_features_record, weights, step_cost_flag, pool, lock, n_human_models, consistent_state_count,\n\u001b[0m\u001b[1;32m    827\u001b[0m                        BEC_summary, summary_count, min_BEC_constraints_running, params.BEC['n_human_models_precomputed'], visited_env_traj_idxs = visited_env_traj_idxs, n_train_demos=np.inf, downsample_threshold=float(\"inf\"), consider_human_models_jointly=True, c=0.001, obj_func_proportion=obj_func_proportion, vars_filename = vars_filename)\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/g/My Drive/Research/Project_proficiency_communication_teams/Codes/augmented_taxi/teams/teams_helpers.py\u001b[0m in \u001b[0;36mobtain_summary_counterfactual_team\u001b[0;34m(data_loc, run_env_loc, particles_demo, teacher_uf_demo, member_id, variable_filter, nonzero_counter, min_subset_constraints_record, min_BEC_constraints, env_record, traj_record, mdp_features_record, weights, step_cost_flag, pool, lock, n_human_models, consistent_state_count, summary, summary_count, min_BEC_constraints_running, n_human_models_precomputed, visited_env_traj_idxs, n_train_demos, downsample_threshold, consider_human_models_jointly, c, obj_func_proportion, vars_filename)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0msummary_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_train_demos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0;31m# print('Knowledge constraints for sampling particles {}'.format(constraint_space_to_sample_human_models))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "params = copy.deepcopy(params_team)\n",
    "\n",
    "teacher_learning_factor = [0.8, 0.8, 0.8]\n",
    "\n",
    "with Manager() as manager:\n",
    "    lock = manager.Lock()\n",
    "\n",
    "    summary_pool = Pool(min(params.n_cpu, 60), initializer=init_pool_processes, initargs=(lock,))\n",
    "\n",
    "    particles_team_teacher, variable_filter, nonzero_counter, min_BEC_constraints_running, visited_env_traj_idxs  = initialize_teaching(params, teacher_learning_factor,  summary_pool, lock)\n",
    "\n",
    "    particles_demo = copy.deepcopy(particles_team_teacher['p1'])\n",
    "\n",
    "    args = particles_demo, summary_pool, lock, variable_filter, min_BEC_constraints_running, visited_env_traj_idxs, summary_pool, lock\n",
    "\n",
    "    demo_mpds, test_mdps, ariable_filter, min_BEC_constraints_running, visited_env_traj_idxs = run_teaching_loop(params, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
