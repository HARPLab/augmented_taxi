{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acadb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skopt.plots import plot_gaussian_process\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "\n",
    "import pymc as pm\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "from pyDOE import lhs, fullfact\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import params_team as params\n",
    "import teams.teams_helpers as team_helpers\n",
    "import analyze_study_3_data as asd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35a3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_objective(x):\n",
    "    \n",
    "    u, delta_c, delta_i = x\n",
    "\n",
    "    mdp_domain = 'augmented_taxi2'\n",
    "    viz_flag = True\n",
    "    learner_update_type = 'no_noise'\n",
    "\n",
    "    # sim params\n",
    "    max_learning_factor = params.max_learning_factor\n",
    "    # initial_learning_factor = copy.deepcopy(learning_params['initial_learning_factor'])\n",
    "    # learning_factor_delta = copy.deepcopy(learning_params['learning_factor_delta'])\n",
    "\n",
    "    # initial_learning_factor = [learning_params[0]]\n",
    "    # learning_factor_delta = [learning_params[1]/2, learning_params[1]]\n",
    "\n",
    "    # learning_factor_delta = [learning_factor_delta_incorrect/2, learning_factor_delta_incorrect]\n",
    "\n",
    "    # learning_factor_delta = [learning_factor_delta_correct, learning_factor_delta_incorrect]\n",
    "\n",
    "    print('initial_learning_factor:', u, 'learning_factor_delta:', [delta_c, delta_i])\n",
    "\n",
    "    # initialize (simulated) learner particle filters\n",
    "    initial_learner_pf = copy.deepcopy(all_learner_pf['p1'])\n",
    "\n",
    "    # prior interaction data\n",
    "    prior_test_constraints = [np.array([[ 1,  0, -4]]), np.array([[-1,  0,  2]])]  # constraints of the first concept/KC\n",
    "    all_test_constraints = {  1: [np.array([[ 1,  0, -4]]), np.array([[-1,  0,  2]])], \\\n",
    "                                2: [np.array([[0, 1, 2]]), np.array([[ 0, -1, -4]])], \\\n",
    "                                3: [np.array([[1, 1, 0]])]}\n",
    "    min_BEC_constraints = [np.array([[1, 1, 0]]), np.array([[-1,  0,  2]]), np.array([[ 0, -1, -4]])]\n",
    "\n",
    "    \n",
    "    # initialize dataframes to save probability data\n",
    "    simulated_interaction_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # simulate teaching loop\n",
    "    prev_kc_id = 1\n",
    "    demo_id = 1\n",
    "    unit_constraints = [np.array([[0, 0, -1]])]\n",
    "    objective = 0\n",
    "    # objective = []\n",
    "\n",
    "    learning_factor = u\n",
    "\n",
    "    # plotting\n",
    "    color_dict = {'demo': 'blue', 'remedial demo': 'purple', 'diagnostic test': 'red',  'remedial test': 'pink', 'diagnostic feedback': 'yellow', 'remedial feedback': 'orange', 'final test': 'green'}\n",
    "    \n",
    "\n",
    "\n",
    "    for user_id, user_interaction_data in prepared_interaction_data.iterrows():\n",
    "\n",
    "        vars_filename_prefix = 'param_fit_user_' + str(user_id) + 'init_lf_' + str(u) + 'lf_delta_' + str(delta_c) + '_' + str(delta_i)\n",
    "        # vars_filename_prefix = 'param_fit_user_' + str(user_id) + 'init_lf_' + str(initial_learning_factor) + 'lf_delta_' + str(learning_factor_delta)\n",
    "        N_final_tests_correct = 0\n",
    "\n",
    "        # print('user_id:', user_id, '.Len user_data:', len(user_interaction_data['kc_id']))\n",
    "\n",
    "        # params to plot\n",
    "        user_interaction_type = []\n",
    "        user_learning_factor = []\n",
    "        user_prob_BEC = []\n",
    "        user_prob_KC = []\n",
    "        user_loop_id = []\n",
    "        concept_end_id = []\n",
    "        plot_id = 0\n",
    "        for loop_id in range(len(user_interaction_data['kc_id'])):\n",
    "            \n",
    "            # print('user_data_kcid:', user_data['kc_id'])\n",
    "            current_kc_id = user_interaction_data['kc_id'][loop_id]\n",
    "            current_interaction_type = user_interaction_data['interaction_types'][loop_id]\n",
    "            # is_opt_response = user_data['is_opt_response'][loop_id]\n",
    "            current_interaction_constraints = user_interaction_data['interaction_constraints'][loop_id]\n",
    "            current_test_constraints = user_interaction_data['test_constraints'][loop_id]   \n",
    "\n",
    "            # Not needed for now!\n",
    "            # if current_interaction_type != 'final test' and current_kc_id <= max_kc:\n",
    "            #     test_constraints = all_test_constraints[current_kc_id]\n",
    "            # else:\n",
    "            #     test_constraints = min_BEC_constraints\n",
    "\n",
    "            if current_kc_id > prev_kc_id:\n",
    "                # learning_factor = copy.deepcopy([initial_learning_factor])\n",
    "                learning_factor = u\n",
    "                # print('New KC! Resetting learning factor to initial value: ', learning_factor)\n",
    "                concept_end_id.append(plot_id-1)\n",
    "\n",
    "            # updates for various interaction types\n",
    "            # Prior\n",
    "            if current_interaction_type == 'prior':\n",
    "                learner_pf = copy.deepcopy(initial_learner_pf)\n",
    "            \n",
    "            # Demo\n",
    "            if current_interaction_type == 'demo':\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = 'Learner belief after demo. Interaction ID:  ' + str(loop_id) + ' for KC: ' + str(current_kc_id), viz_flag = viz_flag, vars_filename=vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "\n",
    "            # Diagnostic Test\n",
    "            if current_interaction_type == 'diagnostic test':\n",
    "                # Nothing changes\n",
    "                response_type = user_interaction_data['test_response_type'][loop_id][0]\n",
    "\n",
    "\n",
    "            # Diagnostic Feedback\n",
    "            if current_interaction_type == 'diagnostic feedback':\n",
    "                # print('response_type: ', response_type)\n",
    "                # if response_type == 'correct':\n",
    "                #     learning_factor[0] = min(learning_factor[0] + learning_factor_delta[0], max_learning_factor)\n",
    "                # elif response_type == 'incorrect':\n",
    "                #     learning_factor[0] = min(learning_factor[0] + learning_factor_delta[1], max_learning_factor)\n",
    "                # else:\n",
    "                #     RuntimeError('Invalid response type')\n",
    "\n",
    "                if response_type == 'correct':\n",
    "                    learning_factor = min(learning_factor + delta_c, max_learning_factor)\n",
    "                elif response_type == 'incorrect':\n",
    "                    learning_factor = min(learning_factor + delta_i, max_learning_factor)\n",
    "                else:\n",
    "                    RuntimeError('Invalid response type')\n",
    "\n",
    "                # updated learner model with corrective feedback\n",
    "                plot_title =  ' Learner after corrective feedback for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename = vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "            # Remedial Demo\n",
    "            if current_interaction_type == 'remedial demo':\n",
    "                plot_title =  'Learner belief after remedial demo. Interaction ID: ' + str(loop_id) + ' for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename=vars_filename_prefix, model_type = learner_update_type)\n",
    "                \n",
    "            # Remedial Test\n",
    "            if current_interaction_type == 'remedial test':\n",
    "                response_type = user_interaction_data['test_response_type'][loop_id][0]\n",
    "\n",
    "            # Remedial Feedback\n",
    "            if current_interaction_type == 'remedial feedback':\n",
    "                # print('response_type: ', response_type)\n",
    "                if response_type == 'correct':\n",
    "                    learning_factor = min(learning_factor + delta_c, max_learning_factor)\n",
    "                elif response_type == 'incorrect':\n",
    "                    learning_factor = min(learning_factor + delta_i, max_learning_factor)\n",
    "                else:\n",
    "                    RuntimeError('Invalid response type')\n",
    "\n",
    "                # updated learner model with corrective feedback\n",
    "                plot_title =  ' Learner after remedial feedback for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename = vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "            # Final Test Performance\n",
    "            if current_interaction_type == 'final test':\n",
    "                if user_interaction_data['is_opt_response'][loop_id] == 1:\n",
    "                    N_final_tests_correct += 1\n",
    "\n",
    "            if 'prior_' not in current_interaction_type:\n",
    "                # calculate probability of correct response\n",
    "                learner_pf.calc_particles_probability(current_test_constraints)\n",
    "                prop_particles_KC = learner_pf.particles_prob_correct\n",
    "\n",
    "\n",
    "                learner_pf.calc_particles_probability(min_BEC_constraints)\n",
    "                prop_particles_BEC = learner_pf.particles_prob_correct\n",
    "                # print('loop_id: ', loop_id, 'interaction: ', current_interaction_type, 'prop_particles_BEC: ', prop_particles_BEC)\n",
    "\n",
    "                # update loop vars\n",
    "                user_interaction_type.append(current_interaction_type)\n",
    "                user_learning_factor.append(learning_factor)\n",
    "                user_prob_BEC.append(prop_particles_BEC)\n",
    "                user_prob_KC.append(prop_particles_KC)\n",
    "                user_loop_id.append(plot_id)\n",
    "                plot_id += 1\n",
    "\n",
    "            # update loop kcid\n",
    "            prev_kc_id = current_kc_id\n",
    "\n",
    "        \n",
    "        \n",
    "        # user_plot_data = pd.DataFrame({'loop_id': user_loop_id, 'interaction_type': user_interaction_type, 'learning_factor': user_learning_factor, 'prob_KC': user_prob_KC, 'prob_BEC': user_prob_BEC})\n",
    "            \n",
    "        # plt.figure(user_id)\n",
    "        # ax0 = plt.gca()\n",
    "        # print('user_id: ', user_id, 'user_plot_data:', user_plot_data)\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='prob_BEC', ax=ax0, color = 'blue').set(title='Obj. func. learning dynamics for user: ' + str(user_id))\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='prob_KC', ax=ax0, color = 'brown')\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='learning_factor', ax=ax0, color = 'green')\n",
    "\n",
    "            \n",
    "        # for id, row in user_plot_data.iterrows():\n",
    "        #     print('id:', id)\n",
    "        #     if row['interaction_type'] != 'prior':\n",
    "        #         plt.axvspan(user_plot_data['loop_id'].iloc[id-1], row['loop_id'], alpha=0.2, color=color_dict[row['interaction_type']])\n",
    "        #         plt.text(row['loop_id']-0.5, 0.3, row['interaction_type'], rotation=90, fontsize=12, weight=\"bold\")\n",
    "\n",
    "        # for id in concept_end_id:\n",
    "        #     plt.axvline(x=id, color='black', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # plt.show()\n",
    "\n",
    "        # calculate final probability\n",
    "        learner_pf.calc_particles_probability(min_BEC_constraints)\n",
    "        prop_particles_BEC = learner_pf.particles_prob_correct\n",
    "\n",
    "        # final test performance\n",
    "        test_perf = N_final_tests_correct/6\n",
    "\n",
    "        # update objective function\n",
    "        objective += np.abs(prop_particles_BEC - test_perf)\n",
    "        # objective.append(prop_particles_BEC)\n",
    "\n",
    "        # print('user_id: ', user_id, 'N_final_tests_correct: ', N_final_tests_correct, 'prop_particles_BEC: ', prop_particles_BEC, 'test_perf: ', test_perf, 'objective: ', prop_particles_BEC - test_perf)\n",
    "\n",
    "        \n",
    "\n",
    "    return objective/len(prepared_interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c987fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abc_data(learner_type = 'low'):\n",
    "\n",
    "    domain = 'at'\n",
    "    filename = 'data/simulation/sim_experiments/parameter_estimation/abc_data_' + learner_type + '_domain_' + domain + '.pickle'\n",
    "\n",
    "    try:\n",
    "        # load data\n",
    "        with open(filename, 'rb') as f:\n",
    "            [prepared_interaction_data, interaction_output] = pickle.load(f)\n",
    "\n",
    "    except:\n",
    "        # prepare train test data\n",
    "        with open ('data/prepared_interaction_data.pickle', 'rb') as f:\n",
    "            all_interaction_data = pickle.load(f)\n",
    "\n",
    "        with open('data/user_data_w_flag.pickle', 'rb') as f:\n",
    "            all_user_data = pickle.load(f)\n",
    "\n",
    "        \n",
    "        if learner_type == 'test':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                                ((all_user_data['N_final_correct_at'] == 2))]\n",
    "        elif learner_type == 'low':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 2) | (all_user_data['N_final_correct_at'] == 3) | (all_user_data['N_final_correct_at'] == 4))]\n",
    "        elif learner_type == 'high':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 5) | (all_user_data['N_final_correct_at'] == 6))]\n",
    "        \n",
    "        # input and output data\n",
    "        unique_user_ids = user_data['user_id'].unique()\n",
    "        prepared_interaction_data = pd.DataFrame()\n",
    "\n",
    "        for user_id in unique_user_ids:\n",
    "            prepared_interaction_data = prepared_interaction_data.append(all_interaction_data[all_interaction_data['user_id'] == user_id], ignore_index=True)\n",
    "\n",
    "        interaction_output = user_data['N_final_correct_at']/6\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([prepared_interaction_data, interaction_output], f)\n",
    "\n",
    "    return prepared_interaction_data, interaction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e09c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(learner_type = 'low'):\n",
    "\n",
    "    domain = 'at'\n",
    "    filename = 'data/simulation/sim_experiments/parameter_estimation/train_test_data_' + learner_type + '_domain_' + domain + '.pickle'\n",
    "\n",
    "    try:\n",
    "        # load train test data\n",
    "        with open(filename, 'rb') as f:\n",
    "            [X_train, X_test, y_train, y_test] = pickle.load(f)\n",
    "    except:\n",
    "        # prepare train test data\n",
    "        with open ('data/prepared_interaction_data.pickle', 'rb') as f:\n",
    "            all_interaction_data = pickle.load(f)\n",
    "\n",
    "        with open('data/user_data_w_flag.pickle', 'rb') as f:\n",
    "            all_user_data = pickle.load(f)\n",
    "\n",
    "        \n",
    "        if learner_type == 'test':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                                ((all_user_data['N_final_correct_at'] == 2))]\n",
    "        elif learner_type == 'low':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 2) | (all_user_data['N_final_correct_at'] == 3) | (all_user_data['N_final_correct_at'] == 4))]\n",
    "        elif learner_type == 'high':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 5) | (all_user_data['N_final_correct_at'] == 6))]\n",
    "            \n",
    "        \n",
    "        # input and output data\n",
    "        unique_user_ids = user_data['user_id'].unique()\n",
    "        prepared_interaction_data = pd.DataFrame()\n",
    "\n",
    "        for user_id in unique_user_ids:\n",
    "            prepared_interaction_data = prepared_interaction_data.append(all_interaction_data[all_interaction_data['user_id'] == user_id], ignore_index=True)\n",
    "\n",
    "        interaction_output = user_data['N_final_correct_at']/6\n",
    "        \n",
    "        # split into test train datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(prepared_interaction_data, interaction_output, test_size=0.25, random_state=0)\n",
    "\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([X_train, X_test, y_train, y_test], f)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8b85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating particles for  p1 with prior knowledge in  no_noise  condition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The number of calls to function has reached maxfev = 400.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "params.team_size = 1\n",
    "params.max_learning_factor = 1.0\n",
    "\n",
    "\n",
    "all_learner_pf = team_helpers.sample_team_pf(params.team_size, params.BEC['n_particles'], params.weights['val'], params.step_cost_flag, team_learning_factor = [0.8], team_prior = params.team_prior, pf_flag='learner', model_type = 'no_noise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7076be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner_type = 'test'\n",
    "# # \n",
    "# prepared_interaction_data, interaction_output = load_abc_data(learner_type = learner_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74df2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model() as model_lv:\n",
    "#     u = pm.Normal(\"u\", sigma=1)\n",
    "#     delta_c = pm.Normal(\"delta_c\", sigma=1)\n",
    "#     delta_i = pm.Normal(\"delta_i\", sigma=1)\n",
    "\n",
    "#     sim = pm.Simulator(\"sim\", simulate_objective, params=(u, delta_c, delta_i), epsilon=10, observed=interaction_output)\n",
    "\n",
    "#     idata_lv = pm.sample_smc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_model = pm.Model()\n",
    "\n",
    "# with basic_model:\n",
    "\n",
    "#     # Priors for unknown model parameters\n",
    "#     u = pm.Normal('u', sigma=1)\n",
    "#     delta_c = pm.Normal('delta_c', sigma=1)\n",
    "#     delta_i = pm.Normal('delta_i', sigma=1)\n",
    "\n",
    "#     # Custom likelihood (negative because PyMC maximizes log likelihood)\n",
    "#     pm.Potential('likelihood', -simulate_objective(u, delta_c, delta_i))\n",
    "    \n",
    "#     # draw 500 posterior samples\n",
    "#     trace = pm.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fbf275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor: initial_learning_factor: initial_learning_factor:initial_learning_factor: initial_learning_factor:initial_learning_factor:initial_learning_factor:initial_learning_factor:  initial_learning_factor:          0.550.55    0.55  0.55  0.550.550.55 0.550.550.550.550.550.60000000000000010.550.6000000000000001 0.6000000000000001 0.60000000000000010.60000000000000010.6000000000000001 0.60000000000000010.6000000000000001 0.60000000000000010.6000000000000001  0.6000000000000001         learning_factor_delta: learning_factor_delta:  learning_factor_delta:  learning_factor_delta:  learning_factor_delta: learning_factor_delta: learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:learning_factor_delta:  learning_factor_delta:learning_factor_delta: learning_factor_delta:learning_factor_delta:learning_factor_delta: learning_factor_delta:learning_factor_delta:  learning_factor_delta:          [0.0, 0.16][0.02, 0.06]   [0.0, 0.08]  [0.0, 0.02]  [0.04, 0.06] [0.02, 0.14][0.04, 0.14][0.08, 0.12][0.06, 0.08][0.06, 0.16][0.1, 0.12][0.0, 0.1][0.14, 0.16][0.1, 0.18][0.02, 0.08][0.0, 0.02]\n",
      "\n",
      "[0.04, 0.08][0.02, 0.14]\n",
      "[0.0, 0.16][0.04, 0.14][0.06, 0.1]\n",
      "[0.06, 0.16]\n",
      "[0.1, 0.12]\n",
      "[0.08, 0.14]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.04]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.1]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.02, 0.08]\n",
      "initial_learning_factor: 0.6000000000000001 initial_learning_factor:learning_factor_delta:  0.6000000000000001[0.0, 0.04]\n",
      " learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.0, 0.1]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.06, 0.1]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.06, 0.16]\n",
      "initial_learning_factor: 0.55 initial_learning_factor:learning_factor_delta:  [0.06, 0.1]0.6000000000000001\n",
      " learning_factor_delta: [0.02, 0.08]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: initial_learning_factor:[0.02, 0.08] 0.6000000000000001 learning_factor_delta:\n",
      " [0.04, 0.16]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.02, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.02, 0.16]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.0, 0.02]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.04, 0.08]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.04, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.04, 0.08]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.04, 0.16]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.06, 0.1]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.08, 0.14]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.08, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.0, 0.04]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.55 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.0, 0.12]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.02, 0.1]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.02, 0.16]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.04]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.04, 0.1]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.12]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.04, 0.16]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.02, 0.1]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.06, 0.12]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.04, 0.1]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.06, 0.12]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.02, 0.16]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.6000000000000001 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.0, 0.06]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.0, 0.06]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.04, 0.16]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.0, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.0, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.04]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.1]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.02, 0.1]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.18]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.6500000000000001 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.04, 0.1]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.04, 0.1]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.04, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.06, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.08, 0.1]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.02, 0.04]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.1, 0.16]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.16, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.02, 0.18]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.0, 0.06]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.04, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.0, 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.0, 0.14]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.06, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.0, 0.14]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.02, 0.04]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.04]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.08, 0.1]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.02, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.12]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.02, 0.18]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.1, 0.16]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.04, 0.12]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.04, 0.18]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.06, 0.14]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.04, 0.12]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.08, 0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.08, 0.18]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.1, 0.16]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.12, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.02, 0.18]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.16, 0.18]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.06, 0.14]\n",
      "initial_learning_factor: initial_learning_factor:0.7500000000000002 0.8000000000000003  learning_factor_delta:learning_factor_delta:  [0.0, 0.08]\n",
      "[0.04, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.08]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.02, 0.06]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.08, 0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.08, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.14]\n",
      "initial_learning_factor: 0.7000000000000002 learning_factor_delta: [0.16, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.12]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.06]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.0, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.12]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.02, 0.12]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.08]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.14]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.04, 0.12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.1, 0.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.12]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.12, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.08, 0.12]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.04, 0.06]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.06]\n",
      "initial_learning_factor: 0.7500000000000002 learning_factor_delta: [0.16, 0.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.06, 0.08]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.06, 0.14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.14]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.08, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.12, 0.18]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.1, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.02]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.12]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.08]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.1]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.06, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.14]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.0, 0.02]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.12]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.1, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.02, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.04, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.12]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.8000000000000003 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.14, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.0, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.14]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.06, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.14, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.1]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.08, 0.1]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.1, 0.16]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.16, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.12, 0.18]\n",
      "initial_learning_factor: 0.8500000000000003 learning_factor_delta: [0.16, 0.18]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0c59be8fe3d3>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Set up multiprocessing Pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m    \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulate_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_to_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Flatten the list of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " ## Custom grid search\n",
    "learner_type = 'test'  # low, high, test\n",
    "dataset_type = 'train'  # train or test\n",
    "N_runs = 2\n",
    "filename_prefix = 'data/simulation/sim_experiments/parameter_estimation/parameter_estimation_output_' + learner_type + '_' + dataset_type\n",
    "\n",
    "# load train test data\n",
    "x_train, x_test, y_train, y_test = load_train_test_data(learner_type = learner_type)\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    prepared_interaction_data = x_train\n",
    "    interaction_output = y_train\n",
    "elif dataset_type == 'test':\n",
    "    prepared_interaction_data = x_test\n",
    "    interaction_output = y_test\n",
    "else:\n",
    "    RuntimeError('Invalid dataset type')\n",
    "\n",
    "params_list = {'initial_learning_factor': np.arange(0.5, 0.9, 0.05), 'learning_factor_delta_correct': np.arange(0.0, 0.2, 0.02), 'learning_factor_delta_incorrect': np.arange(0.0, 0.2, 0.02)}\n",
    "pg = list(ParameterGrid(params_list))\n",
    "params_to_eval = []\n",
    "for pg_ind in pg:\n",
    "    if (pg_ind['learning_factor_delta_incorrect'] > pg_ind['learning_factor_delta_correct']) and (pg_ind['initial_learning_factor'] > 0.5):\n",
    "        # params_to_eval.append(pg_ind)\n",
    "\n",
    "        for run_id in range(N_runs):\n",
    "            params_to_eval.append([pg_ind['initial_learning_factor'], pg_ind['learning_factor_delta_correct'], pg_ind['learning_factor_delta_incorrect']])\n",
    "\n",
    "print(len(params_to_eval))\n",
    "\n",
    "\n",
    "parameter_estimation_output = pd.DataFrame()\n",
    "\n",
    "# Prepare parameters for parallel processing\n",
    "# params_grid_run_eval = [(params_to_eval[params_id]) for params_id in range(len(params_to_eval))]\n",
    "\n",
    "# Set up multiprocessing Pool\n",
    "with Pool() as pool:\n",
    "    results = pool.map(simulate_objective, params_to_eval)\n",
    "\n",
    "# Flatten the list of results\n",
    "objective = [item for sublist in results for item in sublist]\n",
    "\n",
    "for params_id in range(len(params_to_eval)):\n",
    "\n",
    "    for run_id in range(N_runs):\n",
    "\n",
    "        print('Running params_id:', params_id, 'params:', params_to_eval[params_id])\n",
    "        # objective = simulate_objective(params_to_eval[params_id]['initial_learning_factor'], params_to_eval[params_id]['learning_factor_delta_correct'], params_to_eval[params_id]['learning_factor_delta_incorrect'])\n",
    "        # print('Objective:', objective)\n",
    "\n",
    "        output_data = {'params_id': params_id, 'run_id': run_id, 'initial_learning_factor': params_to_eval[params_id]['initial_learning_factor'], 'learning_factor_delta_correct': params_to_eval[params_id]['learning_factor_delta_correct'], \\\n",
    "                       'learning_factor_delta_incorrect': params_to_eval[params_id]['learning_factor_delta_incorrect']}\n",
    "\n",
    "        parameter_estimation_output = parameter_estimation_output.append(output_data, ignore_index=True)\n",
    "\n",
    "parameter_estimation_output['objective'] = objective\n",
    "\n",
    "with open(filename_prefix + '_2.pickle', 'wb') as f:\n",
    "    pickle.dump(parameter_estimation_output, f)\n",
    "\n",
    "parameter_estimation_output.to_csv(filename_prefix + '_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
