{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acadb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skopt.plots import plot_gaussian_process\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "\n",
    "import pymc as pm\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "from pyDOE import lhs, fullfact\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import params_team as params\n",
    "import teams.teams_helpers as team_helpers\n",
    "import analyze_study_3_data as asd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35a3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_objective(x):\n",
    "    \n",
    "    u, delta_c, delta_i = x\n",
    "\n",
    "    mdp_domain = 'augmented_taxi2'\n",
    "    viz_flag = True\n",
    "    learner_update_type = 'no_noise'\n",
    "\n",
    "    # sim params\n",
    "    max_learning_factor = params.max_learning_factor\n",
    "    # initial_learning_factor = copy.deepcopy(learning_params['initial_learning_factor'])\n",
    "    # learning_factor_delta = copy.deepcopy(learning_params['learning_factor_delta'])\n",
    "\n",
    "    # initial_learning_factor = [learning_params[0]]\n",
    "    # learning_factor_delta = [learning_params[1]/2, learning_params[1]]\n",
    "\n",
    "    # learning_factor_delta = [learning_factor_delta_incorrect/2, learning_factor_delta_incorrect]\n",
    "\n",
    "    # learning_factor_delta = [learning_factor_delta_correct, learning_factor_delta_incorrect]\n",
    "\n",
    "    print('initial_learning_factor:', u, 'learning_factor_delta:', [delta_c, delta_i])\n",
    "\n",
    "    # initialize (simulated) learner particle filters\n",
    "    initial_learner_pf = copy.deepcopy(all_learner_pf['p1'])\n",
    "\n",
    "    # prior interaction data\n",
    "    prior_test_constraints = [np.array([[ 1,  0, -4]]), np.array([[-1,  0,  2]])]  # constraints of the first concept/KC\n",
    "    all_test_constraints = {  1: [np.array([[ 1,  0, -4]]), np.array([[-1,  0,  2]])], \\\n",
    "                                2: [np.array([[0, 1, 2]]), np.array([[ 0, -1, -4]])], \\\n",
    "                                3: [np.array([[1, 1, 0]])]}\n",
    "    min_BEC_constraints = [np.array([[1, 1, 0]]), np.array([[-1,  0,  2]]), np.array([[ 0, -1, -4]])]\n",
    "\n",
    "    \n",
    "    # initialize dataframes to save probability data\n",
    "    simulated_interaction_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # simulate teaching loop\n",
    "    prev_kc_id = 1\n",
    "    demo_id = 1\n",
    "    unit_constraints = [np.array([[0, 0, -1]])]\n",
    "    objective = 0\n",
    "    # objective = []\n",
    "\n",
    "    learning_factor = u\n",
    "\n",
    "    # plotting\n",
    "    color_dict = {'demo': 'blue', 'remedial demo': 'purple', 'diagnostic test': 'red',  'remedial test': 'pink', 'diagnostic feedback': 'yellow', 'remedial feedback': 'orange', 'final test': 'green'}\n",
    "    \n",
    "\n",
    "\n",
    "    for user_id, user_interaction_data in prepared_interaction_data.iterrows():\n",
    "\n",
    "        vars_filename_prefix = 'param_fit_user_' + str(user_id) + 'init_lf_' + str(u) + 'lf_delta_' + str(delta_c) + '_' + str(delta_i)\n",
    "        # vars_filename_prefix = 'param_fit_user_' + str(user_id) + 'init_lf_' + str(initial_learning_factor) + 'lf_delta_' + str(learning_factor_delta)\n",
    "        N_final_tests_correct = 0\n",
    "\n",
    "        # print('user_id:', user_id, '.Len user_data:', len(user_interaction_data['kc_id']))\n",
    "\n",
    "        # params to plot\n",
    "        user_interaction_type = []\n",
    "        user_learning_factor = []\n",
    "        user_prob_BEC = []\n",
    "        user_prob_KC = []\n",
    "        user_loop_id = []\n",
    "        concept_end_id = []\n",
    "        plot_id = 0\n",
    "        for loop_id in range(len(user_interaction_data['kc_id'])):\n",
    "            \n",
    "            # print('user_data_kcid:', user_data['kc_id'])\n",
    "            current_kc_id = user_interaction_data['kc_id'][loop_id]\n",
    "            current_interaction_type = user_interaction_data['interaction_types'][loop_id]\n",
    "            # is_opt_response = user_data['is_opt_response'][loop_id]\n",
    "            current_interaction_constraints = user_interaction_data['interaction_constraints'][loop_id]\n",
    "            current_test_constraints = user_interaction_data['test_constraints'][loop_id]   \n",
    "\n",
    "            # Not needed for now!\n",
    "            # if current_interaction_type != 'final test' and current_kc_id <= max_kc:\n",
    "            #     test_constraints = all_test_constraints[current_kc_id]\n",
    "            # else:\n",
    "            #     test_constraints = min_BEC_constraints\n",
    "\n",
    "            if current_kc_id > prev_kc_id:\n",
    "                # learning_factor = copy.deepcopy([initial_learning_factor])\n",
    "                learning_factor = u\n",
    "                # print('New KC! Resetting learning factor to initial value: ', learning_factor)\n",
    "                concept_end_id.append(plot_id-1)\n",
    "\n",
    "            # updates for various interaction types\n",
    "            # Prior\n",
    "            if current_interaction_type == 'prior':\n",
    "                learner_pf = copy.deepcopy(initial_learner_pf)\n",
    "            \n",
    "            # Demo\n",
    "            if current_interaction_type == 'demo':\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = 'Learner belief after demo. Interaction ID:  ' + str(loop_id) + ' for KC: ' + str(current_kc_id), viz_flag = viz_flag, vars_filename=vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "\n",
    "            # Diagnostic Test\n",
    "            if current_interaction_type == 'diagnostic test':\n",
    "                # Nothing changes\n",
    "                response_type = user_interaction_data['test_response_type'][loop_id][0]\n",
    "\n",
    "\n",
    "            # Diagnostic Feedback\n",
    "            if current_interaction_type == 'diagnostic feedback':\n",
    "                # print('response_type: ', response_type)\n",
    "                # if response_type == 'correct':\n",
    "                #     learning_factor[0] = min(learning_factor[0] + learning_factor_delta[0], max_learning_factor)\n",
    "                # elif response_type == 'incorrect':\n",
    "                #     learning_factor[0] = min(learning_factor[0] + learning_factor_delta[1], max_learning_factor)\n",
    "                # else:\n",
    "                #     RuntimeError('Invalid response type')\n",
    "\n",
    "                if response_type == 'correct':\n",
    "                    learning_factor = min(learning_factor + delta_c, max_learning_factor)\n",
    "                elif response_type == 'incorrect':\n",
    "                    learning_factor = min(learning_factor + delta_i, max_learning_factor)\n",
    "                else:\n",
    "                    RuntimeError('Invalid response type')\n",
    "\n",
    "                # updated learner model with corrective feedback\n",
    "                plot_title =  ' Learner after corrective feedback for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename = vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "            # Remedial Demo\n",
    "            if current_interaction_type == 'remedial demo':\n",
    "                plot_title =  'Learner belief after remedial demo. Interaction ID: ' + str(loop_id) + ' for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename=vars_filename_prefix, model_type = learner_update_type)\n",
    "                \n",
    "            # Remedial Test\n",
    "            if current_interaction_type == 'remedial test':\n",
    "                response_type = user_interaction_data['test_response_type'][loop_id][0]\n",
    "\n",
    "            # Remedial Feedback\n",
    "            if current_interaction_type == 'remedial feedback':\n",
    "                # print('response_type: ', response_type)\n",
    "                if response_type == 'correct':\n",
    "                    learning_factor = min(learning_factor + delta_c, max_learning_factor)\n",
    "                elif response_type == 'incorrect':\n",
    "                    learning_factor = min(learning_factor + delta_i, max_learning_factor)\n",
    "                else:\n",
    "                    RuntimeError('Invalid response type')\n",
    "\n",
    "                # updated learner model with corrective feedback\n",
    "                plot_title =  ' Learner after remedial feedback for KC ' + str(current_kc_id)\n",
    "                learner_pf.update(current_interaction_constraints, learning_factor, plot_title = plot_title, viz_flag = viz_flag, vars_filename = vars_filename_prefix, model_type = learner_update_type)\n",
    "\n",
    "            # Final Test Performance\n",
    "            if current_interaction_type == 'final test':\n",
    "                if user_interaction_data['is_opt_response'][loop_id] == 1:\n",
    "                    N_final_tests_correct += 1\n",
    "\n",
    "            if 'prior_' not in current_interaction_type:\n",
    "                # calculate probability of correct response\n",
    "                learner_pf.calc_particles_probability(current_test_constraints)\n",
    "                prop_particles_KC = learner_pf.particles_prob_correct\n",
    "\n",
    "\n",
    "                learner_pf.calc_particles_probability(min_BEC_constraints)\n",
    "                prop_particles_BEC = learner_pf.particles_prob_correct\n",
    "                # print('loop_id: ', loop_id, 'interaction: ', current_interaction_type, 'prop_particles_BEC: ', prop_particles_BEC)\n",
    "\n",
    "                # update loop vars\n",
    "                user_interaction_type.append(current_interaction_type)\n",
    "                user_learning_factor.append(learning_factor)\n",
    "                user_prob_BEC.append(prop_particles_BEC)\n",
    "                user_prob_KC.append(prop_particles_KC)\n",
    "                user_loop_id.append(plot_id)\n",
    "                plot_id += 1\n",
    "\n",
    "            # update loop kcid\n",
    "            prev_kc_id = current_kc_id\n",
    "\n",
    "        \n",
    "        \n",
    "        # user_plot_data = pd.DataFrame({'loop_id': user_loop_id, 'interaction_type': user_interaction_type, 'learning_factor': user_learning_factor, 'prob_KC': user_prob_KC, 'prob_BEC': user_prob_BEC})\n",
    "            \n",
    "        # plt.figure(user_id)\n",
    "        # ax0 = plt.gca()\n",
    "        # print('user_id: ', user_id, 'user_plot_data:', user_plot_data)\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='prob_BEC', ax=ax0, color = 'blue').set(title='Obj. func. learning dynamics for user: ' + str(user_id))\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='prob_KC', ax=ax0, color = 'brown')\n",
    "        # sns.lineplot(data=user_plot_data, x='loop_id', y='learning_factor', ax=ax0, color = 'green')\n",
    "\n",
    "            \n",
    "        # for id, row in user_plot_data.iterrows():\n",
    "        #     print('id:', id)\n",
    "        #     if row['interaction_type'] != 'prior':\n",
    "        #         plt.axvspan(user_plot_data['loop_id'].iloc[id-1], row['loop_id'], alpha=0.2, color=color_dict[row['interaction_type']])\n",
    "        #         plt.text(row['loop_id']-0.5, 0.3, row['interaction_type'], rotation=90, fontsize=12, weight=\"bold\")\n",
    "\n",
    "        # for id in concept_end_id:\n",
    "        #     plt.axvline(x=id, color='black', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # plt.show()\n",
    "\n",
    "        # calculate final probability\n",
    "        learner_pf.calc_particles_probability(min_BEC_constraints)\n",
    "        prop_particles_BEC = learner_pf.particles_prob_correct\n",
    "\n",
    "        # final test performance\n",
    "        test_perf = N_final_tests_correct/6\n",
    "\n",
    "        # update objective function\n",
    "        objective += np.abs(prop_particles_BEC - test_perf)\n",
    "        # objective.append(prop_particles_BEC)\n",
    "\n",
    "        # print('user_id: ', user_id, 'N_final_tests_correct: ', N_final_tests_correct, 'prop_particles_BEC: ', prop_particles_BEC, 'test_perf: ', test_perf, 'objective: ', prop_particles_BEC - test_perf)\n",
    "\n",
    "        \n",
    "\n",
    "    return objective/len(prepared_interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c987fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abc_data(learner_type = 'low'):\n",
    "\n",
    "    domain = 'at'\n",
    "    filename = 'data/simulation/sim_experiments/parameter_estimation/abc_data_' + learner_type + '_domain_' + domain + '.pickle'\n",
    "\n",
    "    try:\n",
    "        # load data\n",
    "        with open(filename, 'rb') as f:\n",
    "            [prepared_interaction_data, interaction_output] = pickle.load(f)\n",
    "\n",
    "    except:\n",
    "        # prepare train test data\n",
    "        with open ('data/prepared_interaction_data.pickle', 'rb') as f:\n",
    "            all_interaction_data = pickle.load(f)\n",
    "\n",
    "        with open('data/user_data_w_flag.pickle', 'rb') as f:\n",
    "            all_user_data = pickle.load(f)\n",
    "\n",
    "        \n",
    "        if learner_type == 'test':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                                ((all_user_data['N_final_correct_at'] == 2))]\n",
    "        elif learner_type == 'low':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 2) | (all_user_data['N_final_correct_at'] == 3) | (all_user_data['N_final_correct_at'] == 4))]\n",
    "        elif learner_type == 'high':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 5) | (all_user_data['N_final_correct_at'] == 6))]\n",
    "        \n",
    "        # input and output data\n",
    "        unique_user_ids = user_data['user_id'].unique()\n",
    "        prepared_interaction_data = pd.DataFrame()\n",
    "\n",
    "        for user_id in unique_user_ids:\n",
    "            prepared_interaction_data = prepared_interaction_data.append(all_interaction_data[all_interaction_data['user_id'] == user_id], ignore_index=True)\n",
    "\n",
    "        interaction_output = user_data['N_final_correct_at']/6\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([prepared_interaction_data, interaction_output], f)\n",
    "\n",
    "    return prepared_interaction_data, interaction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902faec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(learner_type = 'low'):\n",
    "\n",
    "    domain = 'at'\n",
    "    filename = 'data/simulation/sim_experiments/parameter_estimation/train_test_data_' + learner_type + '_domain_' + domain + '.pickle'\n",
    "\n",
    "    try:\n",
    "        # load train test data\n",
    "        with open(filename, 'rb') as f:\n",
    "            [X_train, X_test, y_train, y_test] = pickle.load(f)\n",
    "    except:\n",
    "        # prepare train test data\n",
    "        with open ('data/prepared_interaction_data.pickle', 'rb') as f:\n",
    "            all_interaction_data = pickle.load(f)\n",
    "\n",
    "        with open('data/user_data_w_flag.pickle', 'rb') as f:\n",
    "            all_user_data = pickle.load(f)\n",
    "\n",
    "        \n",
    "        if learner_type == 'test':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                                ((all_user_data['N_final_correct_at'] == 2))]\n",
    "        elif learner_type == 'low':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 2) | (all_user_data['N_final_correct_at'] == 3) | (all_user_data['N_final_correct_at'] == 4))]\n",
    "        elif learner_type == 'high':\n",
    "            user_data = all_user_data[(all_user_data['mislabeled_flag'] == 0) & (all_user_data['loop_condition'] != 'wt') & (all_user_data['loop_condition'] != 'wtcl') & \\\n",
    "                            ((all_user_data['N_final_correct_at'] == 5) | (all_user_data['N_final_correct_at'] == 6))]\n",
    "            \n",
    "        \n",
    "        # input and output data\n",
    "        unique_user_ids = user_data['user_id'].unique()\n",
    "        prepared_interaction_data = pd.DataFrame()\n",
    "\n",
    "        for user_id in unique_user_ids:\n",
    "            prepared_interaction_data = prepared_interaction_data.append(all_interaction_data[all_interaction_data['user_id'] == user_id], ignore_index=True)\n",
    "\n",
    "        interaction_output = user_data['N_final_correct_at']/6\n",
    "        \n",
    "        # split into test train datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(prepared_interaction_data, interaction_output, test_size=0.25, random_state=0)\n",
    "\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([X_train, X_test, y_train, y_test], f)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8b85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating particles for  p1 with prior knowledge in  no_noise  condition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The number of calls to function has reached maxfev = 400.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "params.team_size = 1\n",
    "params.max_learning_factor = 1.0\n",
    "\n",
    "\n",
    "all_learner_pf = team_helpers.sample_team_pf(params.team_size, params.BEC['n_particles'], params.weights['val'], params.step_cost_flag, team_learning_factor = [0.8], team_prior = params.team_prior, pf_flag='learner', model_type = 'no_noise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7076be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner_type = 'test'\n",
    "# # \n",
    "# prepared_interaction_data, interaction_output = load_abc_data(learner_type = learner_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74df2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model() as model_lv:\n",
    "#     u = pm.Normal(\"u\", sigma=1)\n",
    "#     delta_c = pm.Normal(\"delta_c\", sigma=1)\n",
    "#     delta_i = pm.Normal(\"delta_i\", sigma=1)\n",
    "\n",
    "#     sim = pm.Simulator(\"sim\", simulate_objective, params=(u, delta_c, delta_i), epsilon=10, observed=interaction_output)\n",
    "\n",
    "#     idata_lv = pm.sample_smc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_model = pm.Model()\n",
    "\n",
    "# with basic_model:\n",
    "\n",
    "#     # Priors for unknown model parameters\n",
    "#     u = pm.Normal('u', sigma=1)\n",
    "#     delta_c = pm.Normal('delta_c', sigma=1)\n",
    "#     delta_i = pm.Normal('delta_i', sigma=1)\n",
    "\n",
    "#     # Custom likelihood (negative because PyMC maximizes log likelihood)\n",
    "#     pm.Potential('likelihood', -simulate_objective(u, delta_c, delta_i))\n",
    "    \n",
    "#     # draw 500 posterior samples\n",
    "#     trace = pm.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c534fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'params_team' has no attribute 'max_learning_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/sureshkj/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-c5020350cd0b>\", line 10, in simulate_objective\n    max_learning_factor = params.max_learning_factor\nAttributeError: module 'params_team' has no attribute 'max_learning_factor'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-85b9559cb0fc>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Set up multiprocessing Pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m    \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulate_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_to_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Flatten the list of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aug_taxi/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'params_team' has no attribute 'max_learning_factor'"
     ]
    }
   ],
   "source": [
    " ## Custom grid search\n",
    "learner_type = 'test'  # low, high, test\n",
    "dataset_type = 'train'  # train or test\n",
    "N_runs = 2\n",
    "filename_prefix = 'data/simulation/sim_experiments/parameter_estimation/parameter_estimation_output_' + learner_type + '_' + dataset_type\n",
    "\n",
    "# load train test data\n",
    "x_train, x_test, y_train, y_test = load_train_test_data(learner_type = learner_type)\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    prepared_interaction_data = x_train\n",
    "    interaction_output = y_train\n",
    "elif dataset_type == 'test':\n",
    "    prepared_interaction_data = x_test\n",
    "    interaction_output = y_test\n",
    "else:\n",
    "    RuntimeError('Invalid dataset type')\n",
    "\n",
    "params_list = {'initial_learning_factor': np.arange(0.5, 0.9, 0.05), 'learning_factor_delta_correct': np.arange(0.0, 0.2, 0.02), 'learning_factor_delta_incorrect': np.arange(0.0, 0.2, 0.02)}\n",
    "pg = list(ParameterGrid(params_list))\n",
    "params_to_eval = []\n",
    "for pg_ind in pg:\n",
    "    if (pg_ind['learning_factor_delta_incorrect'] > pg_ind['learning_factor_delta_correct']) and (pg_ind['initial_learning_factor'] > 0.5):\n",
    "        # params_to_eval.append(pg_ind)\n",
    "\n",
    "        for run_id in range(N_runs):\n",
    "            params_to_eval.append([pg_ind['initial_learning_factor'], pg_ind['learning_factor_delta_correct'], pg_ind['learning_factor_delta_incorrect']])\n",
    "\n",
    "print(len(params_to_eval))\n",
    "\n",
    "\n",
    "parameter_estimation_output = pd.DataFrame()\n",
    "\n",
    "# Prepare parameters for parallel processing\n",
    "# params_grid_run_eval = [(params_to_eval[params_id]) for params_id in range(len(params_to_eval))]\n",
    "\n",
    "# Set up multiprocessing Pool\n",
    "with Pool() as pool:\n",
    "    results = pool.map(simulate_objective, params_to_eval)\n",
    "\n",
    "# Flatten the list of results\n",
    "objective = [item for sublist in results for item in sublist]\n",
    "\n",
    "for params_id in range(len(params_to_eval)):\n",
    "\n",
    "    for run_id in range(N_runs):\n",
    "\n",
    "        print('Running params_id:', params_id, 'params:', params_to_eval[params_id])\n",
    "        # objective = simulate_objective(params_to_eval[params_id]['initial_learning_factor'], params_to_eval[params_id]['learning_factor_delta_correct'], params_to_eval[params_id]['learning_factor_delta_incorrect'])\n",
    "        # print('Objective:', objective)\n",
    "\n",
    "        output_data = {'params_id': params_id, 'run_id': run_id, 'initial_learning_factor': params_to_eval[params_id]['initial_learning_factor'], 'learning_factor_delta_correct': params_to_eval[params_id]['learning_factor_delta_correct'], \\\n",
    "                       'learning_factor_delta_incorrect': params_to_eval[params_id]['learning_factor_delta_incorrect']}\n",
    "\n",
    "        parameter_estimation_output = parameter_estimation_output.append(output_data, ignore_index=True)\n",
    "\n",
    "parameter_estimation_output['objective'] = objective\n",
    "\n",
    "with open(filename_prefix + '_2.pickle', 'wb') as f:\n",
    "    pickle.dump(parameter_estimation_output, f)\n",
    "\n",
    "parameter_estimation_output.to_csv(filename_prefix + '_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
